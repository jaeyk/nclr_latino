---
title: "EDA"
output:
  html_document:
    df_print: paged
---

# Import pkgs 

```{r}
# Import pkgs
pacman::p_load(
  pdftools,
  tidyverse,
  purrr,
  furrr,
  tm,
  quanteda, 
  here,
  tidytext, # text analysis 
  SnowballC, # stemming 
  textclean, # text preprocessing 
  ggthemes,
  text2vec, # word embedding 
  widyr,
  patchwork, # arranging ggplots
  glue,
  # deep learning 
  text2vec,
  # network graph
  igraph,
  ggraph
)

devtools::install_github("prodriguezsosa/conText")
library(conText)
theme_set(theme_clean())

source(here("functions", "utils.r"))
```

# Import files 

```{r}
load(file = here("processed_data/processed_text.Rdata"))

# Remove unnecessary files 
rm(list = ls()[grep("tf_idf", ls())])

asian_text <- asian_text %>%
  select(date, value, source)

df$source <- "NCLR"

corpus <- bind_rows(df, asian_text)
```

# Word embedding

## Local embedding and matrix 

```{r}
local_glove <- df2vec(corpus)
fcm_cr <- df2cm(corpus)
local_transform <- df2ltm(corpus, fcm_cr, local_glove)

save(local_glove, fcm_cr, local_transform, post_local_glove, 
     file = here("processed_data/context_bg.Rdata"))
```
 
## ALC embedding approach 

### Static 

```{r}
load(here("processed_data/context_bg.Rdata"))

corpus <- corpus %>%
  mutate(group = if_else(source == "NCLR", 1, 0))
  
model1 <- conText(
  formula = black ~ group, 
  data = corpus, 
  text_var = "value", 
  pre_trained = local_glove, 
  transform = TRUE, 
  transform_matrix = local_transform, 
  bootstrap = TRUE, 
  num_bootstraps = 10, 
  stratify_by = c("group"), 
  permute = TRUE, 
  num_permutations = 100, 
  window = 5, 
  valuetype = "fixed", 
  case_insensitive = TRUE, 
  hard_cut = FALSE, 
  verbose = FALSE)

plot_tibble <- model1$normed_betas %>% 
  mutate(Coefficient = c("Latino")) %>% 
  mutate(Coefficient = factor(Coefficient, levels = Coefficient)) 

ggplot(plot_tibble, aes(x = Coefficient, y = Normed_Estimate)) + 
    geom_bar(position = position_dodge(), 
      stat = "identity", width = 0.5) + 
    geom_errorbar(aes(ymin = Normed_Estimate - 
    1.96 * Std.Error, ymax = Normed_Estimate + 1.96 * Std.Error), size = 0.75, width = 0.15, 
    position = position_dodge(0.9)) + 
    ylab("Norm of beta hats") 
    # the stars here are based on the Empirical_Pvalue
   # geom_text(aes(label = c("***", "***")), position = position_dodge(width = 0.9), hjust = 0.5, 
    #vjust = -1, size = 8) + theme(panel.background = element_blank(), axis.text.x = element_text(size = 16, 
    #vjust = 0.5, margin = margin(t = 15, r = 0, b = 15, l = 0)), axis.text.y = element_text(size = 16), 
    #axis.title.y = element_text(size = 18, margin = margin(t = 0, r = 15, b = 0, 
     #   l = 15)), axis.title.x = element_blank(), plot.margin = unit(c(1, 1, 0, 0), 
      #  "cm"))
```

### Dynamic 

## Contrast nearest neighbors 

```{r}
load(here("processed_data/context_bg.Rdata"))

local_vocab <- get_candidates(corpus, local_glove, keyword = "representation", local_transform)
 
seq_out <- get_seq_cos_sim(corpus$value, corpus$date, target = "representation", candidates = local_vocab, pre_trained = local_glove, transform_matrix = local_transform) 

out <- purrr::map_dfr(1:nrow(seq_out), ~simseq2df(seq_out, .))

out$date <- unique(corpus$date)

out %>%
  filter(mean_sim < 1 ) %>%
  ggplot(aes(x = date, y = mean_sim)) +
    geom_point() +
    geom_line(alpha = 0.3)
```

```{r}
visibility <- c("visibility", "representation", "statistics", "data")
identity <- c("pride", "race", "tradition", "identity", "culture")
marginality <- c("discrimination", "poverty", "inequality", "immigrant", "minority")
government <- c("federal", "government", "civil", "fund", "census")
claims <- c("solidarity", "community", "power", "strength", "influence") 
group <- c("white", "black", "negro", "hispanic", "asian")
```

### Get contexts and neighbor comparison 

```{r}
con2nplot(corpus, c("discrimination"), local_glove, local_transform) + labs(title = "Discrimination")

ggsave(here("outputs", "disc_embed.png"), height = 10, width = 20)

con2nplot(corpus, c("opportunity"), local_glove, local_transform) + labs(title = "Opportunity")

ggsave(here("outputs", "opportunity_embed.png"), height = 10, width = 20)

con2nplot(corpus, c("rights"), local_glove, local_transform) + labs(title = "Rights")

ggsave(here("outputs", "rights_embed.png"), height = 10, width = 20)

con2nplot(corpus, c("citizenship"), local_glove, local_transform) + labs(title = "citizenship")

ggsave(here("outputs", "citizenship_embed.png"), height = 10, width = 20)

con2nplot(corpus, c("minority"), local_glove, local_transform) + labs(title = "Minority")

ggsave(here("outputs", "minority_embed.png"), height = 10, width = 20)

con2nplot(corpus, c("representation"), local_glove, local_transform) + labs(title = "Representation")

ggsave(here("outputs", "representation_embed.png"), height = 10, width = 20)
```

The following code was adapted from http://text2vec.org/glove.html

# Split files 

```{r}
df1 <- df_clean %>% filter(date <= 1973)
df2 <- df_clean %>% filter(date >= 1974 & date <= 1977)
df3 <- df_clean %>% filter(date > 1978)

asian1 <- asian_clean %>% filter(date <= 1973)
asian2 <- asian_clean %>% filter(date >= 1974 & date <= 1977)
asian3 <- asian_clean %>% filter(date > 1978)
```

# Building and training model 

```{r}
word_vectors_nclr1 <- df2vec(df1)
word_vectors_nclr2 <- df2vec(df2)
word_vectors_nclr3 <- df2vec(df3)
word_vectors_asian1 <- df2vec(asian1)
word_vectors_asian2 <- df2vec(asian2)
word_vectors_asian3 <- df2vec(asian3)

save(word_vectors_nclr1, word_vectors_nclr2, word_vectors_nclr3, word_vectors_asian1, word_vectors_asian2, word_vectors_asian3, file = here("processed_data", "word_vectors.RData"))
```

## Inspecting related words using word embedding

```{r}
load(here("processed_data", "word_vectors.RData"))

vec2sim(word_vectors_asian3, "black")
```

```{r}
(keyword2plot(word_vectors_nclr2, visibility, 20, "Visibility")) /
(keyword2plot(word_vectors_nclr2, marginality, 20, "Marginality")) / (keyword2plot(word_vectors_nclr2, identity, 20, "Identity")) 

ggsave(here("outputs", "embed_plot_nclr_glove_visible.png"), height = 9, width = 12)

(keyword2plot(word_vectors_nclr2, group, 20, "Group")) /
(keyword2plot(word_vectors_nclr2, claims, 20, "Claim"))

ggsave(here("outputs", "embed_plot_nclr_glove_group.png"), height = 9, width = 12)
```

```{r}
(keyword2plot(word_vectors_asian2, visibility, 20, "Visibility")) /
(keyword2plot(word_vectors_asian2, marginality, 20, "Marginality")) / (keyword2plot(word_vectors_asian2, identity, 20, "Identity")) 

ggsave(here("outputs", "embed_plot_asian_glove_visible.png"), height = 9, width = 12)

(keyword2plot(word_vectors_asian2, group, 20, "Group")) /
(keyword2plot(word_vectors_asian2, claims, 20, "Claim"))

ggsave(here("outputs", "embed_plot_asian_glove_group.png"), height = 9, width = 12)
```