---
title: "EDA"
output:
  html_document:
    df_print: paged
---

# Import pkgs 

```{r}
# Import pkgs
pacman::p_load(
  pdftools,
  tidyverse,
  purrr,
  furrr,
  tm,
  here,
  tidytext, # text analysis 
  SnowballC, # stemming 
  textclean, # text preprocessing 
  ggthemes,
  text2vec, # word embedding 
  widyr,
  patchwork, # arranging ggplots
  glue,
  # deep learning 
  text2vec,
  # network graph
  igraph,
  ggraph
)

theme_set(theme_clean())

source(here("functions", "utils.r"))
```

# Import files 

```{r}
load(file = here("processed_data/processed_text.Rdata"))

# Remove unnecessary files 
rm(list = ls()[grep("tf_idf", ls())])

asian_text <- asian_text %>%
  select(date, value, source)

df$source <- "NCLR"

corpus <- bind_rows(df, asian_text)
```

# Word embedding

## Local embedding and matrix 

```{r}
local_glove <- df2vec(corpus)
fcm_cr <- df2cm(corpus)
local_transform <- df2ltm(corpus, fcm_cr, local_glove)

save(local_glove, fcm_cr, local_transform, 
     file = here("processed_data/context_bg.Rdata"))
```

## Local transformation matrix 

```{r}
# use quanteda's fcm to create an fcm matrix
fcm_cr <- tokens(corpus$value) %>% 
  fcm(context = "window", count = "frequency", 
    window = 6, weights = rep(1, 6), tri = FALSE)

# subset fcm to the vocabulary included in the embeddings
fcm_cr <- fcm_select(fcm_cr, pattern = vocab_pruned$term, selection = "keep")
```

The following code was adapted from http://text2vec.org/glove.html

# Split files 

```{r}
df1 <- df_clean %>% filter(date <= 1973)
df2 <- df_clean %>% filter(date >= 1974 & date <= 1977)
df3 <- df_clean %>% filter(date > 1978)

asian1 <- asian_clean %>% filter(date <= 1973)
asian2 <- asian_clean %>% filter(date >= 1974 & date <= 1977)
asian3 <- asian_clean %>% filter(date > 1978)
```

# Building and training model 

```{r}
word_vectors_nclr1 <- df2vec(df1)
word_vectors_nclr2 <- df2vec(df2)
word_vectors_nclr3 <- df2vec(df3)
word_vectors_asian1 <- df2vec(asian1)
word_vectors_asian2 <- df2vec(asian2)
word_vectors_asian3 <- df2vec(asian3)

save(word_vectors_nclr1, word_vectors_nclr2, word_vectors_nclr3, word_vectors_asian1, word_vectors_asian2, word_vectors_asian3, file = here("processed_data", "word_vectors.RData"))
```

## Inspecting related words using word embedding

```{r}
load(here("processed_data", "word_vectors.RData"))

visibility <- c("visibility", "representation", "absence", "statistics", "data")
identity <- c("pride", "race", "tradition", "identity", "culture")
marginality <- c("discrimination", "poverty", "inequality", "immigrant", "minority")
government <- c("federal", "government", "civil", "fund", "census")
claims <- c("solidarity", "community", "power", "strength", "influence") 
group <- c("white", "black", "negro", "hispanic", "asian")

vec2sim(word_vectors_asian3, "black")
```

```{r}
(keyword2plot(word_vectors_nclr2, visibility, 20, "Visibility")) /
(keyword2plot(word_vectors_nclr2, marginality, 20, "Marginality")) / (keyword2plot(word_vectors_nclr2, identity, 20, "Identity")) 

ggsave(here("outputs", "embed_plot_nclr_glove_visible.png"), height = 9, width = 12)

(keyword2plot(word_vectors_nclr2, group, 20, "Group")) /
(keyword2plot(word_vectors_nclr2, claims, 20, "Claim"))

ggsave(here("outputs", "embed_plot_nclr_glove_group.png"), height = 9, width = 12)
```

```{r}
(keyword2plot(word_vectors_asian2, visibility, 20, "Visibility")) /
(keyword2plot(word_vectors_asian2, marginality, 20, "Marginality")) / (keyword2plot(word_vectors_asian2, identity, 20, "Identity")) 

ggsave(here("outputs", "embed_plot_asian_glove_visible.png"), height = 9, width = 12)

(keyword2plot(word_vectors_asian2, group, 20, "Group")) /
(keyword2plot(word_vectors_asian2, claims, 20, "Claim"))

ggsave(here("outputs", "embed_plot_asian_glove_group.png"), height = 9, width = 12)
```