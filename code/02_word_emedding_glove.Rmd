---
title: "EDA"
output:
  html_document:
    df_print: paged
---

# Import pkgs 

```{r}
# Import pkgs
pacman::p_load(
  pdftools,
  tidyverse,
  purrr,
  furrr,
  tm,
  here,
  tidytext, # text analysis 
  SnowballC, # stemming 
  textclean, # text preprocessing 
  ggthemes,
  text2vec, # word embedding 
  widyr,
  patchwork, # arranging ggplots
  glue,
  # deep learning 
  text2vec
)

theme_set(theme_clean())

source(here("functions", "utils.r"))
```

# Import files 

```{r}
load(file = here("processed_data/processed_text.Rdata"))

# Remove unnecessary files 
rm(list = ls()[grep("tf_idf", ls())])
```

The following code is adapted from: https://cbail.github.io/textasdata/word2vec/rmarkdown/word2vec.html

# Preprocessing data 

```{r}
data("stop_words")

# Remove noise 
df_clean <- df %>%
  mutate(value = value %>%
           # Remove stopwords 
           tm::removeWords(words = stop_words$word) %>%
           # Remove excessive white space
           str_squish()) 

asian_clean <- asian_text %>%
  mutate(value = value %>%
           # Remove stopwords 
           tm::removeWords(words = stop_words$word) %>%
           # Remove excessive white space
           str_squish()) 

save(df_clean, asian_clean, file = here("processed_data", "clean_texts.RData"))
```

The following code was adapted from http://text2vec.org/glove.html

# Split files 

```{r}
df1 <- df_clean %>% filter(date <= 1973)
df2 <- df_clean %>% filter(date >= 1974 & date <= 1977)
df3 <- df_clean %>% filter(date > 1978)

asian1 <- asian_clean %>% filter(date <= 1973)
asian2 <- asian_clean %>% filter(date >= 1974 & date <= 1977)
asian3 <- asian_clean %>% filter(date > 1978)
```

# Building and training model 

```{r}
word_vectors_nclr1 <- df2vec(df1)
word_vectors_nclr2 <- df2vec(df2)
word_vectors_nclr3 <- df2vec(df3)
word_vectors_asian1 <- df2vec(asian1)
word_vectors_asian2 <- df2vec(asian2)
word_vectors_asian3 <- df2vec(asian3)

save(word_vectors_nclr1, word_vectors_nclr2, word_vectors_nclr3, word_vectors_asian1, word_vectors_asian2, word_vectors_asian3, file = here("processed_data", "word_vectors.RData"))
```

## Inspecting related words using word embedding

```{r}
visibility <- c("visibility", "representation", "absence", "statistics", "data")

identity <- c("pride", "race", "tradition", "identity", "culture")

marginality <- c("discrimination", "poverty", "inequality", "immigrant", "minority")

government <- c("federal", "government", "civil", "fund", "census")

claims <- c("solidarity", "community", "power", "strength", "influence") 

group <- c("white", "black", "negro", "hispanic", "asian")
```

```{r}
(keyword2plot(word_vectors_nclr, visibility, 20, "Visibility")) /
(keyword2plot(word_vectors_nclr, marginality, 20, "Marginality")) / (keyword2plot(word_vectors_nclr, identity, 20, "Identity")) 

ggsave(here("outputs", "embed_plot_nclr_glove_visible.png"), height = 9, width = 12)

(keyword2plot(word_vectors_nclr, group, 20, "Group")) /
(keyword2plot(word_vectors_nclr, claims, 20, "Claim"))

ggsave(here("outputs", "embed_plot_nclr_glove_group.png"), height = 9, width = 12)
```

```{r}
(keyword2plot(word_vectors_asian, visibility, 20, "Visibility")) /
(keyword2plot(word_vectors_asian, marginality, 20, "Marginality")) / (keyword2plot(word_vectors_asian, identity, 20, "Identity")) 

ggsave(here("outputs", "embed_plot_asian_glove_visible.png"), height = 9, width = 12)

(keyword2plot(word_vectors_asian, group, 20, "Group")) /
(keyword2plot(word_vectors_asian, claims, 20, "Claim"))

ggsave(here("outputs", "embed_plot_asian_glove_group.png"), height = 9, width = 12)
```